{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import time\n",
        "\n",
        "data_list = []\n",
        "\n",
        "def get_data(url) :\n",
        "  response = requests.get(url)\n",
        "  response.encoding = 'utf-8'\n",
        "\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "  articles = soup.find_all(\"div\", id=\"io_content\")\n",
        "\n",
        "  if articles:\n",
        "      for ar in articles:\n",
        "          h2_tags = ar.find_all('h2')\n",
        "          if h2_tags:\n",
        "              title = []\n",
        "              for h2 in h2_tags:\n",
        "                  title.append(h2.get_text(strip=True))\n",
        "          else:\n",
        "              print(\"No <h2> found in this <div>\")\n",
        "\n",
        "          p_tags = ar.find_all('p')\n",
        "          page = []\n",
        "          if p_tags:\n",
        "              for p in p_tags:\n",
        "                  page.append(p.get_text(strip=True))\n",
        "          else:\n",
        "              print(\"No <p> found in this <div>\")\n",
        "\n",
        "          comment = ar.find_all(\"div\", class_=\"io_center\")\n",
        "          detail = []\n",
        "          if comment:\n",
        "              for c in comment:\n",
        "                  detail.append(c.get_text(strip=True).replace(\"【註釋】\",\"\"))\n",
        "          else:\n",
        "              print(\"No <c> found in this <div>\")\n",
        "\n",
        "          description = ar.find_all(\"div\", class_=\"io_description\")\n",
        "          descript = []\n",
        "          if description:\n",
        "              for d in description:\n",
        "                  for span in d.find_all(\"span\"):\n",
        "                      span.decompose()\n",
        "                  descript.append(d.get_text(strip=True).replace(\"【道德真經註】\",\"\"))\n",
        "          else:\n",
        "              print(\"No <d> found in this <div>\")\n",
        "\n",
        "          Interpretation = ar.find_all(\"div\", class_=\"io_sanskrit\")\n",
        "          I1 = []\n",
        "          I2 = []\n",
        "          if Interpretation:\n",
        "              for I in Interpretation:\n",
        "                  text_I = I.get_text(strip=True)\n",
        "                  if text_I.find(\"【釋文】\") != -1 :\n",
        "                      I1.append(I.get_text(strip=True).replace(\"【釋文】\",\"\"))\n",
        "                  elif text_I.find(\"【解脫】\") != -1 :\n",
        "                      I2.append(I.get_text(strip=True).replace(\"【解脫】\",\"\"))\n",
        "          else:\n",
        "              print(\"No <I> found in this <div>\")\n",
        "\n",
        "          # Append data from this article to data_list\n",
        "          for i in range(len(h2_tags)):\n",
        "              data = {}\n",
        "              data[\"標題\"] = title[i]\n",
        "              data[\"文章\"] = page[i]\n",
        "              data[\"註釋\"] = detail[i]\n",
        "              data[\"白話文\"] = descript[i]\n",
        "              data[\"釋文\"] = I1[i]\n",
        "              data[\"解說\"] = I2[i]\n",
        "              data_list.append(data)\n",
        "  next_page = soup.find(\"span\", class_=\"btn2\")\n",
        "  if next_page and next_page.a :\n",
        "    next_url = f\"https://www.ifreesite.com/scriptures/{next_page.a.get('href')}\"\n",
        "    print(f\"正在爬取:{next_url}\")\n",
        "    time.sleep(1)\n",
        "    get_data(next_url)\n",
        "\n",
        "# Write data_list to JSON Lines file\n",
        "u = \"https://www.ifreesite.com/scriptures/daode-01.htm\"\n",
        "get_data(u)\n",
        "\n",
        "with open(\"data.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for data in data_list:\n",
        "        json.dump(data, f, ensure_ascii=False)\n",
        "        f.write('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJf7OLRjDmWf",
        "outputId": "e6e17415-85f1-4ab7-feee-706ac3ca42ef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在爬取:https://www.ifreesite.com/scriptures/daode-02.htm\n",
            "正在爬取:https://www.ifreesite.com/scriptures/daode-03.htm\n",
            "正在爬取:https://www.ifreesite.com/scriptures/daode-04.htm\n",
            "正在爬取:https://www.ifreesite.com/scriptures/daode-05.htm\n",
            "正在爬取:https://www.ifreesite.com/scriptures/daode-06.htm\n",
            "正在爬取:https://www.ifreesite.com/scriptures/daode-07.htm\n",
            "正在爬取:https://www.ifreesite.com/scriptures/daode-08.htm\n",
            "正在爬取:https://www.ifreesite.com/scriptures/daode-09.htm\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}